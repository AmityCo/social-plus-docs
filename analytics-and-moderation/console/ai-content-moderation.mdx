---
title: "AI Content Moderation"
description: "Leverage AI-powered moderation tools to create safer communities with automated content filtering and intelligent threat detection"
---


Create safer online communities with intelligent, automated content moderation. social.plus leverages advanced AI to scan and filter inappropriate content across text, images, and video, ensuring community standards are maintained without constant manual oversight.

<CardGroup cols={2}>
  <Card title="Pre-Moderation" icon="shield-check" href="#ai-pre-moderation">
    Block inappropriate content before it's published with proactive AI scanning
  </Card>
  <Card title="Post-Moderation" icon="eye" href="#ai-post-moderation">
    Monitor and review published content with intelligent flagging and automated actions
  </Card>
</CardGroup>

## Overview

social.plus offers two complementary AI moderation approaches:

<AccordionGroup>
  <Accordion title="Pre-Moderation" icon="shield-check">
    **Proactive Content Filtering**
    - Content is scanned before publication
    - AI generates confidence scores for detected violations
    - Content blocked if confidence exceeds configured threshold
    - User must modify content to proceed with posting
  </Accordion>
  
  <Accordion title="Post-Moderation" icon="eye">
    **Reactive Content Review**
    - Content is scanned after publication
    - Uses `flagConfidence` and `blockConfidence` thresholds
    - Automatically flags content for review or removes violations
    - Maintains community safety without blocking legitimate content
  </Accordion>
</AccordionGroup>

## Getting Started

<Steps>
  <Step title="Enable AI Moderation">
    Contact our [support team](mailto:support@social.plus) to enable AI content moderation for your application.
  </Step>
  
  <Step title="Configure Settings">
    Set up confidence levels and moderation categories through the social.plus Console.
  </Step>
  
  <Step title="Test & Monitor">
    Test with sample content and monitor moderation effectiveness through analytics.
  </Step>
</Steps>

## AI Pre-Moderation

Prevent inappropriate content from reaching your community with proactive AI scanning. Pre-moderation ensures all content meets your standards before publication.

<Info>
**Current Availability**: Pre-moderation is currently available for image content, with text and video support coming soon.
</Info>

### Image Content Detection

Our AI pre-moderation scans all uploaded images for inappropriate content across four key categories:

<AccordionGroup>
  <Accordion title="Content Categories">
    - **Nudity**: Detection of explicit or inappropriate nudity
    - **Suggestive Content**: Sexually suggestive or provocative imagery
    - **Violence**: Violent or graphic content detection
    - **Disturbing Content**: Content that may be psychologically disturbing
  </Accordion>
</AccordionGroup>

### Configuration

<Steps>
  <Step title="Enable Image Moderation">
    Navigate to **Moderation > Image Moderation** in your social.plus Console and toggle "Enable image moderation" to **ON**.
  </Step>
  
  <Step title="Set Confidence Levels">
    Configure confidence thresholds for each category based on your community standards.
  </Step>
  
  <Step title="Test Configuration">
    Upload test images to verify your confidence settings work as expected.
  </Step>
</Steps>


### Understanding Confidence Levels

<Warning>
**Important**: Confidence levels significantly impact moderation accuracy. Default settings may produce false positives.
</Warning>

Confidence levels represent the AI's certainty in detecting specific content types:

- **Low Confidence (0-30)**: High sensitivity, may block legitimate content
- **Medium Confidence (40-70)**: Balanced approach for most communities  
- **High Confidence (80-100)**: Conservative filtering, may miss some violations

<Tip>
**Recommendation**: Start with medium confidence levels (40-60) and adjust based on your community's needs and false positive rates.
</Tip>


## AI Post-Moderation

Monitor and moderate published content with intelligent detection and automated response workflows. Post-moderation provides comprehensive scanning across all content types while maintaining user experience.

<CardGroup cols={3}>
  <Card title="Text Moderation" icon="message" href="#text-content-detection">
    Detect inappropriate language, hate speech, and harmful text content
  </Card>
  <Card title="Image & Video" icon="image" href="#multimedia-content-detection">
    Scan visual content for policy violations and harmful imagery
  </Card>
  <Card title="Automated Actions" icon="robot" href="#moderation-workflow">
    Configure intelligent responses based on confidence levels
  </Card>
</CardGroup>

### Content Coverage

<AccordionGroup>
  <Accordion title="Supported Content Types">
    **Posts**
    - Text, images, videos, and livestream content
    - Full multimedia content analysis
    - Community-specific rule application
    
    **Comments**  
    - Text and image content scanning
    - Context-aware threat detection
    - Reply chain analysis
    
    **Messages**
    - Text, image, and video content in direct messages
    - Private conversation safety monitoring
    - Bulk message pattern detection
  </Accordion>
</AccordionGroup>

### Text Content Detection

Our AI text moderation identifies and handles various types of inappropriate text content:

<AccordionGroup>
  <Accordion title="Detection Categories" icon="text">
    - **Sexually Explicit Content**: Adult content and explicit sexual references
    - **Suggestive Content**: Sexually suggestive or mature language
    - **Offensive Language**: Hate speech, harassment, and abusive language
    - **Spam Detection**: Promotional content and repetitive messaging
    - **Harmful Content**: Self-harm, violence, and dangerous activities
  </Accordion>
</AccordionGroup>

### Multimedia Content Detection

<Warning>
**Comprehensive Scanning**: Our AI analyzes both static images and video content frame-by-frame for maximum protection.
</Warning>

Advanced visual content analysis covers extensive categories:

<AccordionGroup>
  <Accordion title="Adult Content" icon="eye-slash">
    - Adult Toys, Explicit Nudity, Graphic Nudity
    - Sexual Activity, Sexual Situations, Suggestive Content
    - Swimwear, Underwear, Revealing Clothes
    - Partial Nudity, Illustrated Explicit Nudity
  </Accordion>
  
  <Accordion title="Violence & Harmful Content" icon="shield-exclamation">
    - Graphic Violence, Gore, Physical Violence
    - Weapons, Weapon Violence, Explosions
    - Self Injury, Hanging, Corpses
    - Emaciated Bodies, Visually Disturbing Content
  </Accordion>
  
  <Accordion title="Substance-Related Content" icon="flask">
    - Alcohol, Alcoholic Beverages, Drinking
    - Drugs, Drug Products, Drug Use, Drug Paraphernalia
    - Pills, Smoking, Tobacco, Tobacco Products
  </Accordion>
  
  <Accordion title="Extremist & Hate Content" icon="ban">
    - Extremist, Nazi Party, White Supremacy
    - Hate Symbols, Rude Gestures, Middle Finger
  </Accordion>
  
  <Accordion title="Other Restricted Content" icon="warning">
    - Gambling, Air Crash, Disasters
    - Bare-chested Male (context-dependent)
    - Other contextually inappropriate content
  </Accordion>
</AccordionGroup>

### Understanding Confidence Scores

<AccordionGroup>
  <Accordion title="Confidence Thresholds" icon="sliders">
    **Flag Confidence** (Default: 40)
    - Content scoring above this level gets flagged for review
    - Lower values = more content flagged (higher sensitivity)
    - Recommended range: 30-60 depending on community standards
    
    **Block Confidence** (Default: 80)  
    - Content scoring above this level gets automatically removed
    - Higher values = fewer false positives
    - Recommended range: 70-90 for balanced protection
  </Accordion>
  
  <Accordion title="Score Ranges" icon="chart-bar">
    - **0-39**: Content passes moderation (approved)
    - **40-79**: Content flagged for human review
    - **80-100**: Content automatically blocked/removed
    
    *Note: These ranges use default thresholds and can be customized*
  </Accordion>
</AccordionGroup>

<Info>
**Default Configuration**: All categories start with `flagConfidence: 40` and `blockConfidence: 80`. Monitor your community's content patterns and adjust these values to optimize for your specific needs.
</Info>

### Configuration Parameters

<AccordionGroup>
  <Accordion title="Parameter Reference" icon="gear">
    | Parameter | Type | Description |
    |-----------|------|-------------|
    | `category` | String | Name of the moderation category |
    | `flagConfidence` | Number | Threshold for flagging content (0-100) |
    | `blockConfidence` | Number | Threshold for blocking content (0-100) |
    | `moderationType` | String | Type of content: "text" or "media" |
  </Accordion>
</AccordionGroup>

### API Configuration

<Tabs>
  <Tab title="Regional Endpoints">
    Select the appropriate API endpoint for your region to ensure optimal performance:
    
    | Region | API Endpoint |
    |--------|-------------|  
    | **Europe** | `https://api-eu.social.plus/` |
    | **Singapore** | `https://api-sg.social.plus/` |
    | **United States** | `https://api-us.social.plus/` |
  </Tab>
  
  <Tab title="Configuration APIs">
    <CodeGroup>
      ```json Get Moderation Settings
      GET /api/v3/moderation/settings
      
      Response:
      {
        "categories": [
          {
            "category": "explicit_content",
            "flagConfidence": 40,
            "blockConfidence": 80,
            "moderationType": "media"
          }
        ]
      }
      ```
      
      ```json Update Settings
      PUT /api/v3/moderation/settings
      
      Request:
      {
        "category": "explicit_content",
        "flagConfidence": 50,
        "blockConfidence": 85
      }
      ```
    </CodeGroup>
  </Tab>
</Tabs>

## API Reference

<Note>
For complete API documentation and interactive testing, see our [Moderation API Specification](../../.gitbook/assets/enhance-moderation-api-spec-v3.yml).
</Note>

## Best Practices

<AccordionGroup>
  <Accordion title="Configuration Strategy" icon="gear">
    - **Start Conservative**: Begin with moderate confidence levels and adjust based on results
    - **Monitor Performance**: Track false positive and false negative rates
    - **Community-Specific**: Tailor settings to your community's content standards
    - **Regular Review**: Periodically review and update thresholds as your community evolves
  </Accordion>
  
  <Accordion title="Human Oversight" icon="users">
    - **Review Queue Management**: Ensure consistent review of flagged content
    - **Moderator Training**: Train team on community standards and edge cases
    - **Appeal Process**: Provide clear paths for users to contest moderation decisions
    - **Transparency**: Communicate moderation policies clearly to users
  </Accordion>
  
  <Accordion title="Performance Optimization" icon="gauge">
    - **Batch Processing**: Handle high-volume content efficiently
    - **Regional APIs**: Use geographically appropriate endpoints
    - **Webhook Integration**: Implement real-time event handling for flagged content
    - **Monitoring**: Set up alerts for unusual moderation patterns
  </Accordion>
</AccordionGroup>
