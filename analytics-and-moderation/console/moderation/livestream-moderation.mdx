---
description: Enabling safe and engaging live-streaming experiences.
---

<Info>
Real-time automated analysis of live video frames & audio to surface or auto-enforce against policy violations with minimal latency. Use this guide to enable, configure thresholds, act on incidents, and continuously tune signal quality.
</Info>

## Enable the Feature

<Steps>
  <Step title="Request Access">Contact <a href="mailto:support.asc@amity.co">support</a> to enable livestream moderation.</Step>
  <Step title="Provisioning">Support confirms activation; feature appears in Console settings.</Step>
  <Step title="Shadow Phase (Recommended)">First 1–2 weeks: log results but keep automatic termination conservative.</Step>
</Steps>

<CardGroup cols={3}>
  <Card title="Enable" icon="toggle-on">Provision & price</Card>
  <Card title="Configure" icon="sliders">Per-category thresholds</Card>
  <Card title="Monitor" icon="eye">Status & incident volume</Card>
  <Card title="Intervene" icon="shield">Stop / Delete streams</Card>
  <Card title="Tune" icon="wrench">Threshold calibration</Card>
  <Card title="Audit" icon="clock">Review false positives</Card>
</CardGroup>

## How Detection Works

The system continuously samples frames (and audio signals where applicable) and classifies content into risk categories. Each detection produces category confidence scores (0–100%). Your configured thresholds decide whether a stream:

| Outcome | Trigger | System Action | User Experience |
|---------|---------|---------------|-----------------|
| Pass | All confidences below Flagged thresholds | Continues | Normal playback |
| Flagged | Any category ≥ Flagged threshold but < Terminated | Marked for review (no auto-stop) | Appears normal to viewers |
| Terminated | Any category ≥ Terminated threshold | Broadcast stopped; post soft‑deleted | Appears as normally ended |

## Detection Categories

<AccordionGroup>
  <Accordion title="Pornographic Content">Explicit sexual imagery/acts. Maintain strict thresholds to minimize exposure risk.</Accordion>
  <Accordion title="Violent Content">Graphic violence or severe physical harm. Sensitivity may vary by regional norms.</Accordion>
  <Accordion title="Prohibited Content">Illegal / compliance restricted material (e.g., weapons, contraband). Low tolerance.</Accordion>
  <Accordion title="Inappropriate Content">Borderline or contextual material. Often noisier—calibrate carefully to reduce review overload.</Accordion>
  <Accordion title="Profanity Content">Offensive language or slurs (audio/overlays). Tune to community standards.</Accordion>
</AccordionGroup>

## Configuring Confidence Thresholds

<Tabs>
  <Tab title="Concepts">Two thresholds per category: <strong>Flagged</strong> (human review) and <strong>Terminated</strong> (auto-stop). Flagged &lt;= Terminated must always hold.</Tab>
  <Tab title="Defaults">Flagged 40% · Terminated 75% (balanced starting point).</Tab>
  <Tab title="Precision vs Recall">Lower thresholds catch more violations (higher recall) but increase noise (lower precision). Raise thresholds to reduce false positives.</Tab>
  <Tab title="Calibration Cycle">Collect 1–2 weeks of incidents → Measure False Positive Rate (FPR) & Misses → Adjust ±5–10% → Re-evaluate.</Tab>
  <Tab title="Record Keeping">Log each change: date, category, old/new values, rationale, reviewer.</Tab>
</Tabs>

<Warning>A threshold of 0 (or extremely low) will flood the queue with low-confidence matches, overwhelming moderators and increasing costs.</Warning>

## Tuning Playbook

<AccordionGroup>
  <Accordion title="When to Raise Flagged Threshold">Flag queue FPR > 30% or moderator backlog growing & SLA breach risk.</Accordion>
  <Accordion title="When to Lower Flagged Threshold">Confirmed late detections or missed early intervention opportunities.</Accordion>
  <Accordion title="When to Raise Terminated Threshold">Any unjustified auto-termination (precision drop) or creator complaints validated.</Accordion>
  <Accordion title="When to Lower Terminated Threshold">Severe violations frequently only reaching Flagged state; evidence of slow manual response.</Accordion>
  <Accordion title="Noise Isolation Strategy">Temporarily widen only the lowest-signal category (e.g., Inappropriate) while holding strict categories steady.</Accordion>
</AccordionGroup>

## Acting on Incidents

<Tabs>
  <Tab title="Flag Review Workflow">Open flagged stream → verify frame samples → Decide: Stop, Delete, or Allow.</Tab>
  <Tab title="Stop">Graceful end; keeps audit trail; use for policy breach requiring immediate halt.</Tab>
  <Tab title="Delete">Soft-deletes post & disables playback; apply for severe / disallowed content.</Tab>
  <Tab title="Escalate">Multiple terminations from same broadcaster → review account history & consider broader enforcement.</Tab>
  <Tab title="Threshold Feedback Loop">Each false positive or miss → capture category & confidence to feed tuning log.</Tab>
</Tabs>

## Key Metrics

| Metric | Definition | Target / Signal | Action Trigger |
|--------|-----------|-----------------|----------------|
| Flag Volume per Hour | Flagged streams / hour | Baseline after Week 1 | Sustained spike → investigate attack/content trend |
| False Positive Rate (Flagged) | (Flags cleared as OK) / Flags reviewed | < 30% | Higher → raise Flagged threshold |
| Termination Precision | Valid terminations / Total terminations | > 95% | Drop → raise Terminated threshold & audit samples |
| Miss Incidents | Confirmed violations not flagged/terminated | 0 critical misses | Any miss → lower relevant thresholds or escalate model gap |
| Avg Review Time | Time from flag to moderator decision | Within SLA (e.g., < 5 min) | Rising trend → staffing or threshold adjustment |
| Category Distribution | % flags by category | Stable pattern | Sudden skew → targeted abuse or threshold imbalance |

## Best Practices

<AccordionGroup>
  <Accordion title="Shadow Launch">Run with only Flagged actions (no Terminated) for initial calibration if risk appetite allows.</Accordion>
  <Accordion title="Single Variable Changes">Adjust one category per cycle to attribute impact.</Accordion>
  <Accordion title="Evidence Capture">Retain representative false positives & misses for model feedback.</Accordion>
  <Accordion title="Moderator Training">Provide clear examples per category to align decisions & reduce subjective variance.</Accordion>
  <Accordion title="Creator Guidance">Publish community guidelines emphasizing live content do's & don'ts.</Accordion>
</AccordionGroup>

## Troubleshooting

| Issue | Likely Cause | Resolution |
|-------|--------------|------------|
| Overloaded Flag Queue | Flagged threshold too low / spike event | Raise threshold 5% or add temporary staffing; isolate noisy category |
| Repeated False Terminations | Terminated threshold aggressive or misclassified scenes | Increase threshold; review sample frames; report to support |
| Missed Severe Violation | Threshold too high or model blind spot | Lower thresholds; capture evidence & escalate for model improvement |
| Cost Surge | Increased broadcast minutes + high flag rate | Audit usage, enforce creator guidelines, optimize thresholds |
| Inconsistent Moderator Decisions | Lack of unified rubric | Establish decision matrix & training refresh |
| Slow Review Times | Understaffing or UI overload | Add shift coverage; refine filters; raise thresholds temporarily |


## Next Steps

<CardGroup cols={2}>
  <Card title="Moderation Feed" icon="inbox" href="/analytics-and-moderation/console/user-and-content-management/mod-feed">Central triage & audit</Card>
  <Card title="User History" icon="user" href="/analytics-and-moderation/console/user-and-content-management/user-social-history">Broadcaster behavioral context</Card>
</CardGroup>
