# Audio Messages

Enable voice communication with high-quality audio recordings for expressive and personal messaging experiences.

<CardGroup cols={3}>
  <Card title="Voice Communication" icon="microphone">
    Express emotions and tone naturally
  </Card>
  <Card title="Quick Recording" icon="record-vinyl">
    Fast audio capture and sending
  </Card>
  <Card title="High Quality" icon="volume-high">
    Crystal clear audio playback
  </Card>
</CardGroup>

## Overview

Audio messages provide a personal and expressive way to communicate, allowing users to convey emotions, tone, and detailed information that text alone cannot capture. Perfect for voice notes, quick messages, and situations where typing isn't convenient.

## Key Features

- **High-Quality Recording**: Support for MP3 and WAV formats
- **Quick Send**: Record and send with simple interface
- **Cross-Platform Playback**: Consistent audio experience across devices
- **Caption Support**: Optional text to accompany audio messages
- **Large File Support**: Audio files up to 1GB in size

<Warning>
**Format Support**: Supported audio formats are MP3 and WAV with a maximum file size of 1GB
</Warning>

## Parameters

<ParamField path="subchannelId" type="string" required>
  The unique identifier of the subchannel where the audio message will be sent
</ParamField>

<ParamField path="audioPath" type="string" required>
  The local file path of the audio recording to be sent
</ParamField>

<ParamField path="caption" type="string">
  Optional text caption to accompany the audio message
</ParamField>

<ParamField path="tags" type="string[]">
  Array of arbitrary strings for message categorization and querying
</ParamField>

# Audio Messages

Enable voice communication with high-quality audio recordings for expressive and personal messaging experiences.

<CardGroup cols={3}>
  <Card title="Voice Communication" icon="microphone">
    Express emotions and tone naturally
  </Card>
  <Card title="Quick Recording" icon="record-vinyl">
    Fast audio capture and sending
  </Card>
  <Card title="High Quality" icon="volume-high">
    Crystal clear audio playback
  </Card>
</CardGroup>

## Overview

Audio messages provide a personal and expressive way to communicate, allowing users to convey emotions, tone, and detailed information that text alone cannot capture. Perfect for voice notes, quick messages, and situations where typing isn't convenient.

## Key Features

- **High-Quality Recording**: Support for MP3, WAV, M4A, and AAC formats
- **Real-time Recording**: Record directly from device microphone
- **Waveform Visualization**: Visual representation of audio for better UX
- **Playback Controls**: Play, pause, seek, and speed control
- **Cross-Platform Playback**: Consistent audio experience across devices
- **Caption Support**: Optional text to accompany audio messages
- **Compression**: Automatic audio compression for optimal delivery

<Warning>
**Format Support**: Supported audio formats are MP3, WAV, M4A, and AAC with a maximum file size of 1GB
</Warning>

## Parameters

<ParamField path="subchannelId" type="string" required>
  The unique identifier of the subchannel where the audio message will be sent
</ParamField>

<ParamField path="audioId" type="string" required>
  The file ID of the uploaded audio file. Upload the audio file first to get this ID
</ParamField>

<ParamField path="caption" type="string">
  Optional text caption to accompany the audio message
</ParamField>

<ParamField path="tags" type="string[]">
  Array of arbitrary strings for message categorization and querying
</ParamField>

<ParamField path="duration" type="number">
  Duration of the audio in seconds (automatically calculated)
</ParamField>

## Implementation

<Steps>
<Step title="Record Audio">
  Capture audio using device microphone or select from library
</Step>
<Step title="Upload Audio">
  Upload the audio file to get a file ID
</Step>
<Step title="Create Message">
  Use the file ID to create an audio message with optional caption
</Step>
<Step title="Send to Subchannel">
  The message is automatically sent to the specified subchannel
</Step>
</Steps>

<Tabs>
<Tab title="iOS">
**Version 6**

```swift
import AmitySDK
import AVFoundation

class AudioMessageManager: NSObject {
    private let messageRepository: AmityMessageRepository
    private let fileRepository: AmityFileRepository
    private var audioRecorder: AVAudioRecorder?
    private var audioPlayer: AVAudioPlayer?
    private var recordingSession: AVAudioSession!
    
    init(client: AmityClient) {
        self.messageRepository = AmityMessageRepository(client: client)
        self.fileRepository = AmityFileRepository(client: client)
        super.init()
        setupAudioSession()
    }
    
    private func setupAudioSession() {
        recordingSession = AVAudioSession.sharedInstance()
        
        do {
            try recordingSession.setCategory(.playAndRecord, mode: .default)
            try recordingSession.setActive(true)
        } catch {
            print("Failed to setup audio session: \(error)")
        }
    }
    
    // Record audio message
    func startRecording(completion: @escaping (Result<URL, Error>) -> Void) {
        // Request microphone permission
        recordingSession.requestRecordPermission { [weak self] allowed in
            DispatchQueue.main.async {
                if allowed {
                    self?.beginRecording(completion: completion)
                } else {
                    completion(.failure(AudioError.permissionDenied))
                }
            }
        }
    }
    
    private func beginRecording(completion: @escaping (Result<URL, Error>) -> Void) {
        let audioFilename = getDocumentsDirectory().appendingPathComponent("recording-\(Date().timeIntervalSince1970).m4a")
        
        let settings: [String: Any] = [
            AVFormatIDKey: Int(kAudioFormatMPEG4AAC),
            AVSampleRateKey: 44100,
            AVNumberOfChannelsKey: 2,
            AVEncoderAudioQualityKey: AVAudioQuality.high.rawValue
        ]
        
        do {
            audioRecorder = try AVAudioRecorder(url: audioFilename, settings: settings)
            audioRecorder?.delegate = self
            audioRecorder?.record()
            
            self.recordingCompletion = completion
        } catch {
            completion(.failure(error))
        }
    }
    
    func stopRecording() {
        audioRecorder?.stop()
        audioRecorder = nil
    }
    
    // Send audio message
    func sendAudioMessage(
        audioURL: URL,
        subchannelId: String,
        caption: String? = nil,
        completion: @escaping (Result<AmityMessage, Error>) -> Void
    ) {
        // First upload the audio file
        uploadAudio(audioURL: audioURL) { [weak self] result in
            switch result {
            case .success(let fileId):
                self?.createAudioMessage(
                    fileId: fileId,
                    subchannelId: subchannelId,
                    caption: caption,
                    duration: self?.getAudioDuration(audioURL) ?? 0,
                    completion: completion
                )
            case .failure(let error):
                completion(.failure(error))
            }
        }
    }
    
    private func uploadAudio(
        audioURL: URL,
        completion: @escaping (Result<String, Error>) -> Void
    ) {
        fileRepository.uploadAudio(
            audioURL: audioURL,
            progressHandler: { progress in
                print("Audio upload progress: \(progress)%")
            }
        ) { result in
            switch result {
            case .success(let file):
                completion(.success(file.fileId))
            case .failure(let error):
                completion(.failure(error))
            }
        }
    }
    
    private func createAudioMessage(
        fileId: String,
        subchannelId: String,
        caption: String?,
        duration: TimeInterval,
        completion: @escaping (Result<AmityMessage, Error>) -> Void
    ) {
        messageRepository.createAudioMessage(
            subchannelId: subchannelId,
            audioId: fileId,
            caption: caption,
            duration: duration,
            tags: ["audio", "voice"]
        ) { message, error in
            if let error = error {
                completion(.failure(error))
                return
            }
            
            if let message = message {
                completion(.success(message))
            } else {
                completion(.failure(AudioError.messageCreationFailed))
            }
        }
    }
    
    // Play audio message
    func playAudio(from url: URL, completion: @escaping (Bool) -> Void) {
        do {
            audioPlayer = try AVAudioPlayer(contentsOf: url)
            audioPlayer?.delegate = self
            audioPlayer?.play()
            self.playbackCompletion = completion
        } catch {
            completion(false)
        }
    }
    
    func pauseAudio() {
        audioPlayer?.pause()
    }
    
    func stopAudio() {
        audioPlayer?.stop()
        audioPlayer = nil
    }
    
    private func getDocumentsDirectory() -> URL {
        let paths = FileManager.default.urls(for: .documentDirectory, in: .userDomainMask)
        return paths[0]
    }
    
    private func getAudioDuration(_ url: URL) -> TimeInterval {
        do {
            let audioPlayer = try AVAudioPlayer(contentsOf: url)
            return audioPlayer.duration
        } catch {
            return 0
        }
    }
    
    // Properties for completion handlers
    private var recordingCompletion: ((Result<URL, Error>) -> Void)?
    private var playbackCompletion: ((Bool) -> Void)?
}

// MARK: - AVAudioRecorderDelegate
extension AudioMessageManager: AVAudioRecorderDelegate {
    func audioRecorderDidFinishRecording(_ recorder: AVAudioRecorder, successfully flag: Bool) {
        if flag {
            recordingCompletion?(.success(recorder.url))
        } else {
            recordingCompletion?(.failure(AudioError.recordingFailed))
        }
        recordingCompletion = nil
    }
}

// MARK: - AVAudioPlayerDelegate
extension AudioMessageManager: AVAudioPlayerDelegate {
    func audioPlayerDidFinishPlaying(_ player: AVAudioPlayer, successfully flag: Bool) {
        playbackCompletion?(flag)
        playbackCompletion = nil
    }
}

enum AudioError: Error {
    case permissionDenied
    case recordingFailed
    case messageCreationFailed
    case playbackFailed
}
```
</Tab>

<Tab title="Android">
**Version 6**

```kotlin
import com.amityco.socialcloud.sdk.AmityCoreClient
import com.amityco.socialcloud.sdk.chat.message.AmityMessageRepository
import com.amityco.socialcloud.sdk.core.file.AmityFileRepository
import android.media.MediaRecorder
import android.media.MediaPlayer
import kotlinx.coroutines.*
import java.io.File
import java.io.IOException

class AudioMessageManager(private val client: AmityCoreClient) {
    private val messageRepository = AmityMessageRepository(client)
    private val fileRepository = AmityFileRepository(client)
    private val scope = CoroutineScope(Dispatchers.Main + SupervisorJob())
    
    private var mediaRecorder: MediaRecorder? = null
    private var mediaPlayer: MediaPlayer? = null
    private var currentRecordingFile: File? = null
    
    fun startRecording(
        outputFile: File,
        onSuccess: (File) -> Unit,
        onError: (Exception) -> Unit
    ) {
        try {
            mediaRecorder = MediaRecorder().apply {
                setAudioSource(MediaRecorder.AudioSource.MIC)
                setOutputFormat(MediaRecorder.OutputFormat.MPEG_4)
                setAudioEncoder(MediaRecorder.AudioEncoder.AAC)
                setAudioSamplingRate(44100)
                setAudioEncodingBitRate(128000)
                setOutputFile(outputFile.absolutePath)
                
                prepare()
                start()
            }
            
            currentRecordingFile = outputFile
            onSuccess(outputFile)
        } catch (e: IOException) {
            onError(e)
        }
    }
    
    fun stopRecording(): File? {
        mediaRecorder?.apply {
            stop()
            release()
        }
        mediaRecorder = null
        
        return currentRecordingFile?.also {
            currentRecordingFile = null
        }
    }
    
    fun sendAudioMessage(
        audioFile: File,
        subchannelId: String,
        caption: String? = null,
        onProgress: (Int) -> Unit = {},
        onSuccess: (AmityMessage) -> Unit,
        onError: (Throwable) -> Unit
    ) {
        scope.launch {
            try {
                // Validate audio file
                validateAudioFile(audioFile)
                
                // Upload audio
                val fileId = uploadAudio(audioFile, onProgress)
                
                // Get audio duration
                val duration = getAudioDuration(audioFile)
                
                // Create audio message
                val message = createAudioMessage(
                    fileId = fileId,
                    subchannelId = subchannelId,
                    caption = caption,
                    duration = duration
                )
                
                onSuccess(message)
            } catch (e: Exception) {
                onError(e)
            }
        }
    }
    
    private fun validateAudioFile(file: File) {
        val allowedExtensions = listOf(".mp3", ".wav", ".m4a", ".aac")
        val maxSizeBytes = 1024L * 1024L * 1024L // 1GB
        
        val extension = file.extension.toLowerCase()
        if (!allowedExtensions.contains(".$extension")) {
            throw IllegalArgumentException("Unsupported audio format: $extension")
        }
        
        if (file.length() > maxSizeBytes) {
            throw IllegalArgumentException("Audio file too large: ${file.length()} bytes")
        }
    }
    
    private suspend fun uploadAudio(
        audioFile: File,
        onProgress: (Int) -> Unit
    ): String = withContext(Dispatchers.IO) {
        return@withContext suspendCancellableCoroutine { continuation ->
            fileRepository.uploadAudio(audioFile)
                .progressHandler { progress ->
                    onProgress(progress)
                }
                .build()
                .upload()
                .subscribe(
                    onNext = { file ->
                        continuation.resume(file.getFileId()) {}
                    },
                    onError = { error ->
                        continuation.resumeWithException(error)
                    }
                )
        }
    }
    
    private suspend fun createAudioMessage(
        fileId: String,
        subchannelId: String,
        caption: String?,
        duration: Long
    ): AmityMessage = withContext(Dispatchers.IO) {
        return@withContext suspendCancellableCoroutine { continuation ->
            messageRepository.createAudioMessage(subchannelId)
                .audioId(fileId)
                .caption(caption)
                .duration(duration)
                .tags(listOf("audio", "voice"))
                .build()
                .send()
                .subscribe(
                    onNext = { message ->
                        continuation.resume(message) {}
                    },
                    onError = { error ->
                        continuation.resumeWithException(error)
                    }
                )
        }
    }
    
    // Audio playback methods
    fun playAudio(
        audioUrl: String,
        onPrepared: () -> Unit = {},
        onCompletion: () -> Unit = {},
        onError: (Exception) -> Unit = {}
    ) {
        try {
            mediaPlayer = MediaPlayer().apply {
                setDataSource(audioUrl)
                setOnPreparedListener {
                    start()
                    onPrepared()
                }
                setOnCompletionListener {
                    onCompletion()
                }
                setOnErrorListener { _, _, _ ->
                    onError(Exception("Audio playback error"))
                    true
                }
                prepareAsync()
            }
        } catch (e: Exception) {
            onError(e)
        }
    }
    
    fun pauseAudio() {
        mediaPlayer?.pause()
    }
    
    fun stopAudio() {
        mediaPlayer?.apply {
            stop()
            release()
        }
        mediaPlayer = null
    }
    
    fun seekTo(position: Int) {
        mediaPlayer?.seekTo(position)
    }
    
    fun getCurrentPosition(): Int {
        return mediaPlayer?.currentPosition ?: 0
    }
    
    fun getDuration(): Int {
        return mediaPlayer?.duration ?: 0
    }
    
    private fun getAudioDuration(file: File): Long {
        return try {
            val mediaPlayer = MediaPlayer()
            mediaPlayer.setDataSource(file.absolutePath)
            mediaPlayer.prepare()
            val duration = mediaPlayer.duration.toLong()
            mediaPlayer.release()
            duration
        } catch (e: Exception) {
            0L
        }
    }
    
    fun dispose() {
        stopRecording()
        stopAudio()
        scope.cancel()
    }
}
```
</Tab>

<Tab title="JavaScript">
**Version 6**

```javascript
import { Client, MessageRepository, FileRepository } from '@amityco/js-sdk';

class AudioMessageManager {
    constructor(client) {
        this.messageRepository = new MessageRepository(client);
        this.fileRepository = new FileRepository(client);
        this.mediaRecorder = null;
        this.audioChunks = [];
        this.audioElement = null;
    }
    
    // Record audio using MediaRecorder API
    async startRecording() {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({ 
                audio: {
                    echoCancellation: true,
                    noiseSuppression: true,
                    sampleRate: 44100
                }
            });
            
            this.mediaRecorder = new MediaRecorder(stream, {
                mimeType: 'audio/webm;codecs=opus'
            });
            
            this.audioChunks = [];
            
            this.mediaRecorder.ondataavailable = (event) => {
                if (event.data.size > 0) {
                    this.audioChunks.push(event.data);
                }
            };
            
            this.mediaRecorder.onstop = () => {
                // Stop all tracks
                stream.getTracks().forEach(track => track.stop());
            };
            
            this.mediaRecorder.start(1000); // Collect data every second
            return true;
        } catch (error) {
            throw new Error(`Failed to start recording: ${error.message}`);
        }
    }
    
    stopRecording() {
        return new Promise((resolve, reject) => {
            if (!this.mediaRecorder || this.mediaRecorder.state !== 'recording') {
                reject(new Error('No active recording'));
                return;
            }
            
            this.mediaRecorder.onstop = () => {
                const audioBlob = new Blob(this.audioChunks, { 
                    type: 'audio/webm' 
                });
                const audioFile = new File([audioBlob], 'audio-message.webm', { 
                    type: 'audio/webm' 
                });
                resolve(audioFile);
            };
            
            this.mediaRecorder.stop();
        });
    }
    
    async sendAudioMessage({
        audioFile,
        subchannelId,
        caption = null,
        onProgress = () => {},
        tags = ['audio', 'voice']
    }) {
        try {
            // Validate audio file
            this.validateAudioFile(audioFile);
            
            // Upload audio
            const fileId = await this.uploadAudio(audioFile, onProgress);
            
            // Get audio duration
            const duration = await this.getAudioDuration(audioFile);
            
            // Create message
            const message = await this.createAudioMessage({
                fileId,
                subchannelId,
                caption,
                duration,
                tags
            });
            
            return { success: true, message };
        } catch (error) {
            console.error('Failed to send audio message:', error);
            return { success: false, error: error.message };
        }
    }
    
    validateAudioFile(file) {
        const allowedTypes = [
            'audio/mpeg',     // MP3
            'audio/wav',      // WAV
            'audio/mp4',      // M4A
            'audio/aac',      // AAC
            'audio/webm'      // WebM
        ];
        const maxSize = 1024 * 1024 * 1024; // 1GB
        
        if (!allowedTypes.includes(file.type)) {
            throw new Error(`Unsupported audio type: ${file.type}`);
        }
        
        if (file.size > maxSize) {
            throw new Error(`Audio too large: ${(file.size / 1024 / 1024).toFixed(2)}MB. Max: 1GB`);
        }
    }
    
    async uploadAudio(file, onProgress) {
        return new Promise((resolve, reject) => {
            const liveObject = this.fileRepository.uploadAudio(file);
            
            liveObject.on('dataUpdated', (file) => {
                if (file.uploadProgress) {
                    onProgress(file.uploadProgress);
                }
                
                if (file.fileId) {
                    resolve(file.fileId);
                }
            });
            
            liveObject.on('dataError', (error) => {
                reject(new Error(`Audio upload failed: ${error.message}`));
            });
        });
    }
    
    async createAudioMessage({ fileId, subchannelId, caption, duration, tags }) {
        return new Promise((resolve, reject) => {
            const liveObject = this.messageRepository.createAudioMessage({
                subchannelId,
                audioId: fileId,
                caption,
                duration,
                tags
            });
            
            liveObject.on('dataUpdated', (message) => {
                if (message.messageId) {
                    resolve(message);
                }
            });
            
            liveObject.on('dataError', (error) => {
                reject(new Error(`Audio message creation failed: ${error.message}`));
            });
        });
    }
    
    // Audio playback methods
    async playAudio(audioUrl) {
        if (this.audioElement) {
            this.audioElement.pause();
        }
        
        this.audioElement = new Audio(audioUrl);
        
        try {
            await this.audioElement.play();
        } catch (error) {
            throw new Error(`Audio playback failed: ${error.message}`);
        }
    }
    
    pauseAudio() {
        if (this.audioElement) {
            this.audioElement.pause();
        }
    }
    
    stopAudio() {
        if (this.audioElement) {
            this.audioElement.pause();
            this.audioElement.currentTime = 0;
        }
    }
    
    seekTo(time) {
        if (this.audioElement) {
            this.audioElement.currentTime = time;
        }
    }
    
    getCurrentTime() {
        return this.audioElement ? this.audioElement.currentTime : 0;
    }
    
    getDuration() {
        return this.audioElement ? this.audioElement.duration : 0;
    }
    
    // Get audio duration from file
    async getAudioDuration(file) {
        return new Promise((resolve) => {
            const audio = new Audio();
            audio.addEventListener('loadedmetadata', () => {
                URL.revokeObjectURL(audio.src);
                resolve(audio.duration);
            });
            audio.addEventListener('error', () => {
                URL.revokeObjectURL(audio.src);
                resolve(0);
            });
            audio.src = URL.createObjectURL(file);
        });
    }
}

// Usage example
class VoiceMessageUI {
    constructor(client, subchannelId) {
        this.audioManager = new AudioMessageManager(client);
        this.subchannelId = subchannelId;
        this.isRecording = false;
        this.setupUI();
    }
    
    setupUI() {
        const container = document.getElementById('voice-message-container');
        
        const recordButton = document.createElement('button');
        recordButton.id = 'record-button';
        recordButton.textContent = '🎤 Record';
        recordButton.onclick = () => this.toggleRecording();
        
        const uploadButton = document.createElement('input');
        uploadButton.type = 'file';
        uploadButton.accept = 'audio/*';
        uploadButton.style.display = 'none';
        uploadButton.onchange = (e) => this.handleFileUpload(e.target.files[0]);
        
        const uploadLabel = document.createElement('label');
        uploadLabel.textContent = '📁 Upload Audio';
        uploadLabel.onclick = () => uploadButton.click();
        uploadLabel.style.cursor = 'pointer';
        
        container.appendChild(recordButton);
        container.appendChild(uploadButton);
        container.appendChild(uploadLabel);
        
        this.recordButton = recordButton;
    }
    
    async toggleRecording() {
        if (this.isRecording) {
            try {
                const audioFile = await this.audioManager.stopRecording();
                this.recordButton.textContent = '🎤 Record';
                this.isRecording = false;
                
                await this.sendAudio(audioFile);
            } catch (error) {
                console.error('Failed to stop recording:', error);
            }
        } else {
            try {
                await this.audioManager.startRecording();
                this.recordButton.textContent = '⏹️ Stop';
                this.isRecording = true;
            } catch (error) {
                alert(`Recording failed: ${error.message}`);
            }
        }
    }
    
    async handleFileUpload(file) {
        if (file) {
            await this.sendAudio(file);
        }
    }
    
    async sendAudio(audioFile) {
        const progressContainer = this.showProgress();
        
        try {
            const result = await this.audioManager.sendAudioMessage({
                audioFile,
                subchannelId: this.subchannelId,
                caption: 'Voice message',
                onProgress: (progress) => {
                    this.updateProgress(progressContainer, progress);
                }
            });
            
            if (result.success) {
                this.showSuccess('Audio sent successfully!');
            } else {
                this.showError(result.error);
            }
        } catch (error) {
            this.showError(`Failed to send audio: ${error.message}`);
        } finally {
            this.hideProgress(progressContainer);
        }
    }
    
    showProgress() {
        const container = document.createElement('div');
        container.className = 'audio-progress';
        container.innerHTML = `
            <div class="progress-bar">
                <div class="progress-fill" style="width: 0%"></div>
            </div>
            <span>Uploading audio...</span>
        `;
        document.body.appendChild(container);
        return container;
    }
    
    updateProgress(container, progress) {
        const fill = container.querySelector('.progress-fill');
        fill.style.width = `${progress}%`;
    }
    
    hideProgress(container) {
        container.remove();
    }
    
    showSuccess(message) {
        console.log(message);
        // Show success notification
    }
    
    showError(message) {
        console.error(message);
        // Show error notification
    }
}
```
</Tab>

<Tab title="TypeScript">
**Version 6**

```typescript
import { 
    Client, 
    MessageRepository, 
    FileRepository,
    AmityMessage,
    AmityFile 
} from '@amityco/ts-sdk';

interface AudioMessageParams {
    audioFile: File;
    subchannelId: string;
    caption?: string;
    tags?: string[];
}

interface SendAudioResult {
    success: boolean;
    message?: AmityMessage;
    error?: string;
}

interface AudioRecordingOptions {
    echoCancellation?: boolean;
    noiseSuppression?: boolean;
    sampleRate?: number;
    channelCount?: number;
}

class AudioMessageManager {
    private messageRepository: MessageRepository;
    private fileRepository: FileRepository;
    private mediaRecorder: MediaRecorder | null = null;
    private audioChunks: Blob[] = [];
    private currentAudio: HTMLAudioElement | null = null;
    
    constructor(private client: Client) {
        this.messageRepository = new MessageRepository(client);
        this.fileRepository = new FileRepository(client);
    }
    
    async startRecording(options: AudioRecordingOptions = {}): Promise<void> {
        try {
            const stream = await navigator.mediaDevices.getUserMedia({
                audio: {
                    echoCancellation: options.echoCancellation ?? true,
                    noiseSuppression: options.noiseSuppression ?? true,
                    sampleRate: options.sampleRate ?? 44100,
                    channelCount: options.channelCount ?? 1
                }
            });
            
            const mimeType = this.getSupportedMimeType();
            this.mediaRecorder = new MediaRecorder(stream, { mimeType });
            
            this.audioChunks = [];
            
            this.mediaRecorder.addEventListener('dataavailable', (event) => {
                if (event.data.size > 0) {
                    this.audioChunks.push(event.data);
                }
            });
            
            this.mediaRecorder.addEventListener('stop', () => {
                stream.getTracks().forEach(track => track.stop());
            });
            
            this.mediaRecorder.start(1000);
        } catch (error) {
            throw new Error(`Recording initialization failed: ${error instanceof Error ? error.message : 'Unknown error'}`);
        }
    }
    
    async stopRecording(): Promise<File> {
        if (!this.mediaRecorder || this.mediaRecorder.state !== 'recording') {
            throw new Error('No active recording session');
        }
        
        return new Promise((resolve, reject) => {
            this.mediaRecorder!.addEventListener('stop', () => {
                const audioBlob = new Blob(this.audioChunks, { 
                    type: this.getSupportedMimeType() 
                });
                
                const timestamp = Date.now();
                const extension = this.getFileExtension();
                const audioFile = new File(
                    [audioBlob], 
                    `audio-${timestamp}.${extension}`, 
                    { type: audioBlob.type }
                );
                
                resolve(audioFile);
            });
            
            this.mediaRecorder!.addEventListener('error', (event) => {
                reject(new Error(`Recording failed: ${event.error}`));
            });
            
            this.mediaRecorder!.stop();
        });
    }
    
    async sendAudioMessage({
        audioFile,
        subchannelId,
        caption,
        tags = ['audio', 'voice']
    }: AudioMessageParams): Promise<SendAudioResult> {
        try {
            // Validate audio file
            this.validateAudioFile(audioFile);
            
            // Upload audio and get file ID
            const fileId = await this.uploadAudioFile(audioFile);
            
            // Get audio duration
            const duration = await this.getAudioDuration(audioFile);
            
            // Create and send audio message
            const message = await this.createAudioMessage({
                fileId,
                subchannelId,
                caption,
                duration,
                tags
            });
            
            return { success: true, message };
        } catch (error) {
            console.error('Audio message send failed:', error);
            return { 
                success: false, 
                error: error instanceof Error ? error.message : 'Unknown error'
            };
        }
    }
    
    private validateAudioFile(file: File): void {
        const allowedTypes = [
            'audio/mpeg',     // MP3
            'audio/wav',      // WAV
            'audio/mp4',      // M4A
            'audio/aac',      // AAC
            'audio/webm',     // WebM
            'audio/ogg'       // OGG
        ];
        const maxSizeBytes = 1024 * 1024 * 1024; // 1GB
        
        if (!allowedTypes.includes(file.type)) {
            throw new Error(
                `Invalid audio type: ${file.type}. Supported: ${allowedTypes.join(', ')}`
            );
        }
        
        if (file.size > maxSizeBytes) {
            throw new Error(
                `Audio too large: ${(file.size / 1024 / 1024).toFixed(2)}MB. Maximum: 1GB`
            );
        }
    }
    
    private async uploadAudioFile(file: File): Promise<string> {
        return new Promise((resolve, reject) => {
            const liveObject = this.fileRepository.uploadAudio(file);
            
            liveObject.on('dataUpdated', (uploadedFile: AmityFile) => {
                if (uploadedFile.fileId) {
                    resolve(uploadedFile.fileId);
                }
            });
            
            liveObject.on('dataError', (error: Error) => {
                reject(new Error(`Audio upload failed: ${error.message}`));
            });
        });
    }
    
    private async createAudioMessage(params: {
        fileId: string;
        subchannelId: string;
        caption?: string;
        duration: number;
        tags: string[];
    }): Promise<AmityMessage> {
        return new Promise((resolve, reject) => {
            const liveObject = this.messageRepository.createAudioMessage({
                subchannelId: params.subchannelId,
                audioId: params.fileId,
                caption: params.caption,
                duration: params.duration,
                tags: params.tags
            });
            
            liveObject.on('dataUpdated', (message: AmityMessage) => {
                if (message.messageId) {
                    resolve(message);
                }
            });
            
            liveObject.on('dataError', (error: Error) => {
                reject(new Error(`Message creation failed: ${error.message}`));
            });
        });
    }
    
    // Audio playback methods
    async playAudio(audioUrl: string): Promise<void> {
        if (this.currentAudio) {
            this.currentAudio.pause();
        }
        
        this.currentAudio = new Audio(audioUrl);
        
        try {
            await this.currentAudio.play();
        } catch (error) {
            throw new Error(`Audio playback failed: ${error instanceof Error ? error.message : 'Unknown error'}`);
        }
    }
    
    pauseAudio(): void {
        this.currentAudio?.pause();
    }
    
    stopAudio(): void {
        if (this.currentAudio) {
            this.currentAudio.pause();
            this.currentAudio.currentTime = 0;
        }
    }
    
    seekTo(time: number): void {
        if (this.currentAudio) {
            this.currentAudio.currentTime = time;
        }
    }
    
    getCurrentTime(): number {
        return this.currentAudio?.currentTime ?? 0;
    }
    
    getDuration(): number {
        return this.currentAudio?.duration ?? 0;
    }
    
    // Utility methods
    private getSupportedMimeType(): string {
        const types = [
            'audio/webm;codecs=opus',
            'audio/webm',
            'audio/ogg;codecs=opus',
            'audio/ogg',
            'audio/mp4',
            'audio/mpeg'
        ];
        
        for (const type of types) {
            if (MediaRecorder.isTypeSupported(type)) {
                return type;
            }
        }
        
        return 'audio/webm'; // Fallback
    }
    
    private getFileExtension(): string {
        const mimeType = this.getSupportedMimeType();
        const extensions: Record<string, string> = {
            'audio/webm': 'webm',
            'audio/ogg': 'ogg',
            'audio/mp4': 'm4a',
            'audio/mpeg': 'mp3'
        };
        
        return extensions[mimeType.split(';')[0]] || 'webm';
    }
    
    private async getAudioDuration(file: File): Promise<number> {
        return new Promise((resolve) => {
            const audio = new Audio();
            
            audio.addEventListener('loadedmetadata', () => {
                URL.revokeObjectURL(audio.src);
                resolve(audio.duration);
            });
            
            audio.addEventListener('error', () => {
                URL.revokeObjectURL(audio.src);
                resolve(0);
            });
            
            audio.src = URL.createObjectURL(file);
        });
    }
}

// React TypeScript component example
import React, { useState, useRef, useCallback } from 'react';

interface AudioRecorderProps {
    client: Client;
    subchannelId: string;
    onAudioSent: (message: AmityMessage) => void;
    onError: (error: string) => void;
}

const AudioRecorder: React.FC<AudioRecorderProps> = ({
    client,
    subchannelId,
    onAudioSent,
    onError
}) => {
    const [isRecording, setIsRecording] = useState(false);
    const [uploading, setUploading] = useState(false);
    const [recordingTime, setRecordingTime] = useState(0);
    
    const audioManager = useRef(new AudioMessageManager(client));
    const recordingTimer = useRef<NodeJS.Timeout>();
    
    const startRecording = useCallback(async () => {
        try {
            await audioManager.current.startRecording();
            setIsRecording(true);
            
            // Start timer
            recordingTimer.current = setInterval(() => {
                setRecordingTime(prev => prev + 1);
            }, 1000);
        } catch (error) {
            onError(`Failed to start recording: ${error instanceof Error ? error.message : 'Unknown error'}`);
        }
    }, [onError]);
    
    const stopRecording = useCallback(async () => {
        try {
            const audioFile = await audioManager.current.stopRecording();
            setIsRecording(false);
            setRecordingTime(0);
            
            if (recordingTimer.current) {
                clearInterval(recordingTimer.current);
            }
            
            await sendAudio(audioFile);
        } catch (error) {
            onError(`Failed to stop recording: ${error instanceof Error ? error.message : 'Unknown error'}`);
        }
    }, [onError]);
    
    const sendAudio = async (audioFile: File) => {
        setUploading(true);
        
        try {
            const result = await audioManager.current.sendAudioMessage({
                audioFile,
                subchannelId,
                caption: 'Voice message',
                tags: ['voice', 'recording']
            });
            
            if (result.success && result.message) {
                onAudioSent(result.message);
            } else {
                onError(result.error || 'Failed to send audio');
            }
        } catch (error) {
            onError(error instanceof Error ? error.message : 'Upload failed');
        } finally {
            setUploading(false);
        }
    };
    
    const handleFileChange = async (event: React.ChangeEvent<HTMLInputElement>) => {
        const file = event.target.files?.[0];
        if (file) {
            await sendAudio(file);
        }
    };
    
    const formatTime = (seconds: number): string => {
        const mins = Math.floor(seconds / 60);
        const secs = seconds % 60;
        return `${mins}:${secs.toString().padStart(2, '0')}`;
    };
    
    return (
        <div className="audio-recorder">
            <div className="recording-controls">
                {!isRecording ? (
                    <button 
                        onClick={startRecording} 
                        disabled={uploading}
                        className="record-button"
                    >
                        🎤 Record
                    </button>
                ) : (
                    <div className="recording-active">
                        <button onClick={stopRecording} className="stop-button">
                            ⏹️ Stop
                        </button>
                        <span className="recording-time">
                            🔴 {formatTime(recordingTime)}
                        </span>
                    </div>
                )}
                
                <input
                    type="file"
                    accept="audio/*"
                    onChange={handleFileChange}
                    disabled={uploading || isRecording}
                    style={{ display: 'none' }}
                    id="audio-upload"
                />
                <label htmlFor="audio-upload" className="upload-button">
                    📁 Upload Audio
                </label>
            </div>
            
            {uploading && (
                <div className="upload-status">
                    <div className="spinner"></div>
                    <span>Sending audio message...</span>
                </div>
            )}
        </div>
    );
};

export { AudioMessageManager, AudioRecorder };
```
</Tab>

<Tab title="Flutter">
**Version 0.2**

```dart
import 'package:amity_sdk/amity_sdk.dart';
import 'package:flutter/material.dart';
import 'package:audio_waveforms/audio_waveforms.dart';
import 'package:file_picker/file_picker.dart';
import 'package:permission_handler/permission_handler.dart';
import 'dart:io';

class AudioMessageService {
  final AmityClient _client;
  late final AmityMessageRepository _messageRepository;
  late final AmityFileRepository _fileRepository;
  
  AudioMessageService(this._client) {
    _messageRepository = AmityMessageRepository(_client);
    _fileRepository = AmityFileRepository(_client);
  }
  
  Future<AmityMessage> sendAudioMessage({
    required String subchannelId,
    required File audioFile,
    String? caption,
    List<String> tags = const ['audio', 'voice'],
    Function(int)? onProgress,
  }) async {
    try {
      // Validate audio file
      await _validateAudioFile(audioFile);
      
      // Upload audio
      final fileId = await _uploadAudio(audioFile, onProgress);
      
      // Get audio duration
      final duration = await _getAudioDuration(audioFile);
      
      // Create message
      final message = await _createAudioMessage(
        fileId: fileId,
        subchannelId: subchannelId,
        caption: caption,
        duration: duration,
        tags: tags,
      );
      
      return message;
    } catch (e) {
      throw AudioMessageException('Failed to send audio: ${e.toString()}');
    }
  }
  
  Future<void> _validateAudioFile(File file) async {
    const allowedExtensions = ['.mp3', '.wav', '.m4a', '.aac'];
    const maxSizeBytes = 1024 * 1024 * 1024; // 1GB
    
    final extension = file.path.toLowerCase().split('.').last;
    if (!allowedExtensions.any((ext) => ext.contains(extension))) {
      throw ArgumentError('Unsupported audio type. Use MP3, WAV, M4A, or AAC.');
    }
    
    final fileSize = await file.length();
    if (fileSize > maxSizeBytes) {
      throw ArgumentError('Audio too large. Maximum size is 1GB.');
    }
  }
  
  Future<String> _uploadAudio(File file, Function(int)? onProgress) async {
    final completer = Completer<String>();
    
    _fileRepository.uploadAudio(file)
      .progressHandler((progress) {
        onProgress?.call(progress);
      })
      .build()
      .upload()
      .listen(
        (fileData) {
          if (fileData.fileId != null) {
            completer.complete(fileData.fileId!);
          }
        },
        onError: (error) {
          completer.completeError(error);
        },
      );
    
    return completer.future;
  }
  
  Future<AmityMessage> _createAudioMessage({
    required String fileId,
    required String subchannelId,
    String? caption,
    required int duration,
    required List<String> tags,
  }) async {
    final completer = Completer<AmityMessage>();
    
    _messageRepository.createAudioMessage(subchannelId)
      .audioId(fileId)
      .caption(caption)
      .duration(duration)
      .tags(tags)
      .build()
      .send()
      .listen(
        (message) {
          completer.complete(message);
        },
        onError: (error) {
          completer.completeError(error);
        },
      );
    
    return completer.future;
  }
  
  Future<int> _getAudioDuration(File file) async {
    // This would typically use a plugin like audioplayers
    // For now, return a placeholder
    return 0;
  }
}

class AudioRecorderWidget extends StatefulWidget {
  final String subchannelId;
  final Function(AmityMessage) onAudioSent;
  final Function(String) onError;
  
  const AudioRecorderWidget({
    Key? key,
    required this.subchannelId,
    required this.onAudioSent,
    required this.onError,
  }) : super(key: key);
  
  @override
  _AudioRecorderWidgetState createState() => _AudioRecorderWidgetState();
}

class _AudioRecorderWidgetState extends State<AudioRecorderWidget> {
  late final AudioMessageService _audioService;
  late final RecorderController _recorderController;
  
  bool _isRecording = false;
  bool _isPaused = false;
  bool _sending = false;
  int _uploadProgress = 0;
  String? _recordingPath;
  
  @override
  void initState() {
    super.initState();
    _audioService = AudioMessageService(AmityClient.instance);
    _recorderController = RecorderController();
  }
  
  @override
  void dispose() {
    _recorderController.dispose();
    super.dispose();
  }
  
  @override
  Widget build(BuildContext context) {
    return Column(
      children: [
        // Waveform display
        if (_isRecording || _isPaused)
          Container(
            height: 80,
            padding: const EdgeInsets.all(8.0),
            child: AudioWaveforms(
              size: Size(MediaQuery.of(context).size.width - 32, 80),
              recorderController: _recorderController,
              waveStyle: const WaveStyle(
                waveColor: Colors.blue,
                showDurationLabel: true,
                spacing: 8.0,
                showBottom: false,
                extendWaveform: true,
                showMiddleLine: false,
              ),
            ),
          ),
        
        // Control buttons
        Row(
          mainAxisAlignment: MainAxisAlignment.spaceEvenly,
          children: [
            // Record/Stop button
            IconButton(
              icon: Icon(_isRecording ? Icons.stop : Icons.mic),
              iconSize: 32,
              color: _isRecording ? Colors.red : Colors.blue,
              onPressed: _sending ? null : _toggleRecording,
              tooltip: _isRecording ? 'Stop Recording' : 'Start Recording',
            ),
            
            // Pause/Resume button (only during recording)
            if (_isRecording || _isPaused)
              IconButton(
                icon: Icon(_isPaused ? Icons.play_arrow : Icons.pause),
                iconSize: 32,
                onPressed: _togglePause,
                tooltip: _isPaused ? 'Resume' : 'Pause',
              ),
            
            // Upload from file button
            IconButton(
              icon: const Icon(Icons.folder),
              iconSize: 32,
              onPressed: _sending ? null : _selectAudioFile,
              tooltip: 'Select Audio File',
            ),
            
            // Send button (when recording is complete)
            if (_recordingPath != null && !_isRecording)
              IconButton(
                icon: const Icon(Icons.send),
                iconSize: 32,
                color: Colors.green,
                onPressed: _sending ? null : _sendRecording,
                tooltip: 'Send Audio',
              ),
          ],
        ),
        
        // Upload progress
        if (_sending) ...[
          const SizedBox(height: 8),
          LinearProgressIndicator(
            value: _uploadProgress / 100,
            backgroundColor: Colors.grey[300],
            valueColor: AlwaysStoppedAnimation<Color>(
              Theme.of(context).primaryColor,
            ),
          ),
          const SizedBox(height: 4),
          Text('Uploading audio... $_uploadProgress%'),
        ],
      ],
    );
  }
  
  Future<void> _toggleRecording() async {
    if (_isRecording) {
      await _stopRecording();
    } else {
      await _startRecording();
    }
  }
  
  Future<void> _startRecording() async {
    // Request microphone permission
    final permission = await Permission.microphone.request();
    if (permission != PermissionStatus.granted) {
      widget.onError('Microphone permission denied');
      return;
    }
    
    try {
      final path = await _recorderController.start();
      setState(() {
        _isRecording = true;
        _isPaused = false;
        _recordingPath = path;
      });
    } catch (e) {
      widget.onError('Failed to start recording: $e');
    }
  }
  
  Future<void> _stopRecording() async {
    try {
      final path = await _recorderController.stop();
      setState(() {
        _isRecording = false;
        _isPaused = false;
        _recordingPath = path;
      });
    } catch (e) {
      widget.onError('Failed to stop recording: $e');
    }
  }
  
  Future<void> _togglePause() async {
    if (_isPaused) {
      await _recorderController.resume();
      setState(() => _isPaused = false);
    } else {
      await _recorderController.pause();
      setState(() => _isPaused = true);
    }
  }
  
  Future<void> _selectAudioFile() async {
    try {
      final result = await FilePicker.platform.pickFiles(
        type: FileType.audio,
        allowMultiple: false,
      );
      
      if (result != null && result.files.isNotEmpty) {
        final filePath = result.files.first.path;
        if (filePath != null) {
          await _sendAudioFile(File(filePath));
        }
      }
    } catch (e) {
      widget.onError('Failed to select audio file: $e');
    }
  }
  
  Future<void> _sendRecording() async {
    if (_recordingPath != null) {
      await _sendAudioFile(File(_recordingPath!));
    }
  }
  
  Future<void> _sendAudioFile(File audioFile) async {
    setState(() {
      _sending = true;
      _uploadProgress = 0;
    });
    
    try {
      final message = await _audioService.sendAudioMessage(
        subchannelId: widget.subchannelId,
        audioFile: audioFile,
        caption: 'Voice message',
        onProgress: (progress) {
          setState(() {
            _uploadProgress = progress;
          });
        },
      );
      
      widget.onAudioSent(message);
      
      // Clear recording
      setState(() {
        _recordingPath = null;
      });
      
      // Show success feedback
      ScaffoldMessenger.of(context).showSnackBar(
        const SnackBar(
          content: Text('Audio sent successfully!'),
          backgroundColor: Colors.green,
        ),
      );
    } catch (e) {
      widget.onError(e.toString());
      
      // Show error feedback
      ScaffoldMessenger.of(context).showSnackBar(
        SnackBar(
          content: Text('Failed to send audio: $e'),
          backgroundColor: Colors.red,
        ),
      );
    } finally {
      setState(() {
        _sending = false;
        _uploadProgress = 0;
      });
    }
  }
}

class AudioMessageException implements Exception {
  final String message;
  AudioMessageException(this.message);
  
  @override
  String toString() => 'AudioMessageException: $message';
}

// Audio player widget for received messages
class AudioPlayerWidget extends StatefulWidget {
  final AmityMessage message;
  
  const AudioPlayerWidget({Key? key, required this.message}) : super(key: key);
  
  @override
  _AudioPlayerWidgetState createState() => _AudioPlayerWidgetState();
}

class _AudioPlayerWidgetState extends State<AudioPlayerWidget> {
  late final PlayerController _playerController;
  bool _isPlaying = false;
  bool _isLoading = true;
  
  @override
  void initState() {
    super.initState();
    _playerController = PlayerController();
    _initializePlayer();
  }
  
  Future<void> _initializePlayer() async {
    try {
      final audioData = widget.message.data as Map<String, dynamic>?;
      final audioUrl = audioData?['fileUrl'] as String?;
      
      if (audioUrl != null) {
        await _playerController.preparePlayer(path: audioUrl);
        setState(() => _isLoading = false);
      }
    } catch (e) {
      setState(() => _isLoading = false);
    }
  }
  
  @override
  void dispose() {
    _playerController.dispose();
    super.dispose();
  }
  
  @override
  Widget build(BuildContext context) {
    if (_isLoading) {
      return const Center(child: CircularProgressIndicator());
    }
    
    return Container(
      padding: const EdgeInsets.all(12.0),
      decoration: BoxDecoration(
        color: Colors.grey[100],
        borderRadius: BorderRadius.circular(12.0),
      ),
      child: Column(
        children: [
          // Waveform display
          AudioFileWaveforms(
            size: Size(MediaQuery.of(context).size.width - 64, 50),
            playerController: _playerController,
            waveformType: WaveformType.fitWidth,
            playerWaveStyle: const PlayerWaveStyle(
              fixedWaveColor: Colors.grey,
              liveWaveColor: Colors.blue,
              spacing: 6,
            ),
          ),
          
          const SizedBox(height: 8),
          
          // Playback controls
          Row(
            mainAxisAlignment: MainAxisAlignment.center,
            children: [
              IconButton(
                icon: Icon(_isPlaying ? Icons.pause : Icons.play_arrow),
                onPressed: _togglePlayback,
              ),
              IconButton(
                icon: const Icon(Icons.stop),
                onPressed: _stopPlayback,
              ),
            ],
          ),
        ],
      ),
    );
  }
  
  Future<void> _togglePlayback() async {
    if (_isPlaying) {
      await _playerController.pausePlayer();
    } else {
      await _playerController.startPlayer();
    }
    setState(() => _isPlaying = !_isPlaying);
  }
  
  Future<void> _stopPlayback() async {
    await _playerController.stopPlayer();
    setState(() => _isPlaying = false);
  }
}
```
</Tab>
</Tabs>